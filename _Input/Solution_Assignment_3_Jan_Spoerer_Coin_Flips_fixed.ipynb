{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "import math\n",
    "\n",
    "import operator\n",
    "\n",
    "number_of_experiments = 5\n",
    "number_of_coin_tosses_per_trial = 25\n",
    "\n",
    "maximum_number_of_iterations = 10\n",
    "\n",
    "# Experiment properties: Prob to choose coin A for the trial\n",
    "p_A = 0.5\n",
    "p_B = 1 - p_A\n",
    "\n",
    "# Coin properties: Prob for heads and tails\n",
    "p_heads_A = 0.9\n",
    "p_heads_B = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use and modify and download the expectation-maximization (EM) Python program for two coins, as developed in the lecture. Generate an unrepresentative series of exactly $n = 5 \\times 25$ total coin flips (5 times 25 flips with the randomly selected coin), given two coins thrown with equal probability (1/2), but with different heads probabilities, $p_A$ (coin A), and $p_B$ (coin B), respectively. Choose and fix a single parameter combination within $0.1 < p_A < 0.9$ and $0.1 < p_B < 0.9.$ This means to generate a series of (H)eads and (T)ails that is virtually incompatible, i.e. highly unlikely, given the ground truth $\\theta = (p_A, p_B)$ of your choice, yet being a valid realization (instance) of the underlying fair double-coin process. Once this highly unlikely (say, unlucky) realization is found and generated, analyze this given instance with the EM algorithm. The EM steps will show convergence to some (MLE) estimates of ${p'}_A$ and ${p'}_B$, which best represent the unlikely dataset but deviate substantially from $p_A$ and $p_B$.\n",
    "The solution with the largest value of\n",
    "$$score = min\\left[abs\\left(log\\left({p'}_A/p_A\\right)\\right), abs\\left(log\\left({p'}_B/p_B\\right)\\right)\\right]$$\n",
    "(that you need to compute and print) wins a price, handed over by the lecturer -- but only if this value is unique among the submissions. If it is not, the 2nd largest score wins, if unique, and so on. If there is no winner, the present may, sadly, be thrown out of one randomly selected window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "## Data generation \n",
    "## Show expectation maximization to some MLE estimates of  $ð‘'_ð´$  and  $ð‘'_ðµ$ , which best represent the unlikely dataset but deviate substantially from $ð‘_ð´$  and  $ð‘_ðµ$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rolls_data(number_of_experiments, number_of_coin_tosses_per_trial, p_heads_A, p_heads_B, p_A, p_B):\n",
    "    list_rolls = []\n",
    "    A_number_of_heads = 0\n",
    "    B_number_of_heads = 0\n",
    "    A_number_of_tails = 0\n",
    "    B_number_of_tails = 0\n",
    "\n",
    "    for i in range(0, number_of_experiments):\n",
    "        trial = ''\n",
    "        A = 0\n",
    "        # Choose coin: p fixed for single trial\n",
    "        if random.uniform(0, 1) < p_A: \n",
    "            p = p_heads_A\n",
    "            A = 1\n",
    "        else:\n",
    "            p = p_heads_B\n",
    "            A = 0\n",
    "\n",
    "        for j in range(0, number_of_coin_tosses_per_trial):\n",
    "            outcome = random.uniform(0, 1)\n",
    "            if outcome < p:\n",
    "                trial += \"H\"\n",
    "                if A == 1: #was zero before\n",
    "                    A_number_of_heads += 1\n",
    "                else:\n",
    "                    B_number_of_heads += 1\n",
    "            else: \n",
    "                trial += \"T\"\n",
    "                if A == 1: #was zero before\n",
    "                    A_number_of_tails += 1\n",
    "                else:\n",
    "                    B_number_of_tails += 1\n",
    "        list_rolls.append(trial)\n",
    "\n",
    "    return list_rolls, A_number_of_heads, B_number_of_heads, A_number_of_tails, B_number_of_tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the calculation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coin_likelihood(trial, bias):\n",
    "    # P(X | Z, theta)\n",
    "    numHeads = trial.count(\"H\")\n",
    "    flips = len(trial)\n",
    "\n",
    "    return pow(bias, numHeads) * pow(1 - bias, flips -numHeads)\n",
    "\n",
    "def e_step(rolls, theta_A, theta_B):\n",
    "    \"\"\"Produce the expected value for heads_A, tails_A, heads_B, tails_B \n",
    "    over the rolls given the coin biases\"\"\"\n",
    "    heads_A, tails_A = 0, 0\n",
    "    heads_B, tails_B = 0, 0\n",
    "    \n",
    "    for trial in rolls:\n",
    "        likelihood_A = coin_likelihood(trial, theta_A)\n",
    "        likelihood_B = coin_likelihood(trial, theta_B)\n",
    "        p_A = likelihood_A / (likelihood_A + likelihood_B)\n",
    "        p_B = likelihood_B / (likelihood_A + likelihood_B)\n",
    "        heads_A += p_A * trial.count(\"H\")\n",
    "        tails_A += p_A * trial.count(\"T\")\n",
    "        heads_B += p_B * trial.count(\"H\")\n",
    "        tails_B += p_B * trial.count(\"T\")\n",
    "        \n",
    "    return heads_A, tails_A, heads_B, tails_B\n",
    "\n",
    "def m_step(heads_A, tails_A, heads_B, tails_B):\n",
    "    \"\"\"Produce the values for theta that maximize the expected number of heads/tails\"\"\"\n",
    "    theta_A = heads_A / (heads_A + tails_A)\n",
    "    theta_B = heads_B / (heads_B + tails_B)\n",
    "\n",
    "    return theta_A, theta_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call expectation maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def coin_em(rolls, theta_A=None, theta_B=None, maxiter=maximum_number_of_iterations):\n",
    "    # Initial Guess\n",
    "    theta_A = theta_A or random.random()\n",
    "    theta_B = theta_B or random.random()\n",
    "    # theta vector\n",
    "    thetas = [(theta_A, theta_B)]\n",
    "    # Iterate\n",
    "    for c in range(maxiter):\n",
    "        # print(\"#%d:\\t%0.3f %0.3f\" % (c, theta_A, theta_B))\n",
    "        heads_A, tails_A, heads_B, tails_B = e_step(rolls, theta_A, theta_B)\n",
    "        theta_A, theta_B = m_step(heads_A, tails_A, heads_B, tails_B)\n",
    "        \n",
    "    thetas.append((theta_A,theta_B))    \n",
    "\n",
    "    return thetas, (theta_A, theta_B)\n",
    "    \n",
    "def coin_marginal_likelihood(rolls, biasA, biasB):\n",
    "    # P(X | theta)\n",
    "    likelihoods = []\n",
    "    for trial in rolls:\n",
    "        h = trial.count(\"H\")\n",
    "        t = trial.count(\"T\")\n",
    "        likelihoodA = coin_likelihood(trial, biasA)\n",
    "        likelihoodB = coin_likelihood(trial, biasB)\n",
    "        likelihoods.append(np.log(0.5 * (likelihoodA + likelihoodB)))\n",
    "\n",
    "    return sum(likelihoods)\n",
    "\n",
    "def calculate_score(p_estimated_head_A, p_estimated_head_B, p_heads_A, p_heads_B):\n",
    "    try:\n",
    "        score = min(\n",
    "            abs(math.log(p_estimated_head_A/p_heads_A)),\n",
    "            abs(math.log(p_estimated_head_B/p_heads_B))\n",
    "        )\n",
    "    except:\n",
    "        score = 0\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot_coin_likelihood(rolls, thetas=None):\n",
    "    # grid\n",
    "    xvals = np.linspace(0.01,0.99,100)\n",
    "    yvals = np.linspace(0.01,0.99,100)\n",
    "    X,Y = np.meshgrid(xvals, yvals)\n",
    "    \n",
    "    # compute likelihood\n",
    "    Z = []\n",
    "    for i,r in enumerate(X):\n",
    "        z = []\n",
    "        for j,c in enumerate(r):\n",
    "            z.append(coin_marginal_likelihood(rolls,c,Y[i][j]))\n",
    "        Z.append(z)\n",
    "    \n",
    "    # plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    C = plt.contour(X,Y,Z,150)\n",
    "    cbar = plt.colorbar(C)\n",
    "    plt.title(r\"Likelihood $\\log p(\\mathcal{X}|\\theta_A,\\theta_B)$\", fontsize=20)\n",
    "    plt.xlabel(r\"$\\theta_A$\", fontsize=20)\n",
    "    plt.ylabel(r\"$\\theta_B$\", fontsize=20)\n",
    "    \n",
    "    # plot thetas\n",
    "    if thetas is not None:\n",
    "        thetas = np.array(thetas)\n",
    "        plt.plot(thetas[:,0], thetas[:,1], '-k', lw=2.0)\n",
    "        plt.plot(thetas[:,0], thetas[:,1], 'ok', ms=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'highest_score': 4.312103, 'best_rolls': ['TTTTTTTTTTTTTTTTTTTTTTTTT', 'TTTTTTTTTTTTTTTHTTTTTTTTT', 'TTTTTTTTTTTTTTTTTTTTTTTTT', 'TTTTTTTTTTTTTTTTTTTTTTTTT', 'TTTTTTTTTTTTTTTTTTTTTTTTT'], 'winning_p_heads_A': 0.9999, 'winning_p_heads_B': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "number_of_brute_force_tests = 50000\n",
    "results = {\n",
    "    'score': [],\n",
    "    'list_rolls': [],\n",
    "    'A_number_of_heads': [],\n",
    "    'B_number_of_heads': [],\n",
    "    'A_number_of_tails': [],\n",
    "    'B_number_of_tails': [],\n",
    "    'p_heads_A': [],\n",
    "    'p_heads_B': []\n",
    "}\n",
    "\n",
    "for instance_of_brute_force_test in range(0, number_of_brute_force_tests):\n",
    "    for p_heads_A in [0.9999]: #, 0.8, 0.7, 0.6, 0.5]:\n",
    "        for p_heads_B in [0.0001]: #, 0.2, 0.3, 0.4]:\n",
    "            list_rolls, A_number_of_heads, B_number_of_heads, A_number_of_tails, B_number_of_tails = generate_rolls_data(number_of_experiments, number_of_coin_tosses_per_trial, p_heads_A, p_heads_B, p_A, p_B)\n",
    "            # plot_coin_likelihood(list_rolls, thetas)\n",
    "            thetas, _ = coin_em(list_rolls, 0.8, 0.5, maxiter=maximum_number_of_iterations)\n",
    "\n",
    "            score = calculate_score(\n",
    "                p_estimated_head_A=thetas[-1][0], \n",
    "                p_estimated_head_B=thetas[-1][1], \n",
    "                p_heads_A=p_heads_A,\n",
    "                p_heads_B=p_heads_B\n",
    "            )\n",
    "\n",
    "            results['score'].append(round(score, 6))\n",
    "            results['list_rolls'].append(list_rolls)\n",
    "            results['A_number_of_heads'].append(A_number_of_heads)\n",
    "            results['B_number_of_heads'].append(B_number_of_heads)\n",
    "            results['A_number_of_tails'].append(A_number_of_tails)\n",
    "            results['B_number_of_tails'].append(B_number_of_tails)\n",
    "            results['p_heads_A'].append(p_heads_A)\n",
    "            results['p_heads_B'].append(p_heads_B)\n",
    "    \n",
    "def find_best_score(results):\n",
    "\n",
    "    index_of_higest_score, highest_score = max(enumerate(results['score']), key=operator.itemgetter(1))\n",
    "    \n",
    "    best_rolls = results['list_rolls'][index_of_higest_score]\n",
    "    winning_p_heads_A = results['p_heads_A'][index_of_higest_score]\n",
    "    winning_p_heads_B = results['p_heads_B'][index_of_higest_score]\n",
    "    \n",
    "    return {\n",
    "        'highest_score': highest_score, \n",
    "        'best_rolls': best_rolls, \n",
    "        'winning_p_heads_A': winning_p_heads_A, \n",
    "        'winning_p_heads_B': winning_p_heads_B\n",
    "    }\n",
    "\n",
    "print(find_best_score(results))\n",
    "\n",
    "# Compare with\n",
    "# print(\"MLE estimates from data (finite sample size estimates!):\")\n",
    "# MLE_p_A, MLE_p_B = m_step(A_number_of_heads, A_number_of_tails, B_number_of_heads, B_number_of_tails)\n",
    "# print(\"%0.3f %0.3f\" % (MLE_p_A, MLE_p_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
